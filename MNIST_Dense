import numpy as np 
import pandas as pd 
import keras
from keras.utils import to_categorical
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from tensorflow.keras import layers
from tensorflow.keras import regularizers
import matplotlib.pyplot as plt

(train_images , train_labels), (test_images , test_labels) = mnist.load_data()
train_images = train_images.reshape((60000 , 28 * 28))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000 , 28 * 28))
test_images = test_images.astype('float32') / 255

train_labels = to_categorical (train_labels)
test_labels = to_categorical (test_labels)

x_train= train_images[:40000]
x_validation=train_images[40000:]
x_labels = train_labels[:40000]
y_validation = train_labels[40000:]
#########################################################################
model1 = Sequential()
model1.add(Dense(512, activation='relu', input_shape=(28 * 28,)))
model1.add(Dense(64, activation='relu'))
model1.add(Dense(10, activation='softmax'))

model1.compile (optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])
history1=model1.fit(train_images , train_labels ,validation_data=(x_validation,y_validation),epochs=10, batch_size=128)

test_loss , test_accuracy = model1.evaluate(test_images , test_labels)

history_dict1 = history1.history
history_dict1.keys()

org_loss_values = history_dict1['loss']
org_val_loss_values = history_dict1['val_loss']
plt.plot(org_loss_values, 'bo', label='Training loss')
plt.plot(org_val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss of original method')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

org_acc_values = history_dict1['accuracy']
org_val_acc_values = history_dict1['val_accuracy']
plt.plot(org_acc_values, 'bo', label='Training accuracy')
plt.plot(org_val_acc_values, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy of original method')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()
###################################################################################3
model2 = Sequential()
model2.add(Dense(32, activation='relu', input_shape=(28 * 28,)))
model1.add(Dense(12, activation='relu'))
model2.add(Dense(10, activation='softmax'))

model2.compile (optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

history2=model2.fit(train_images , train_labels ,validation_data=(x_validation,y_validation),epochs=10, batch_size=128)

test_loss , test_accuracy = model2.evaluate(test_images , test_labels)
history_dict2 = history2.history
history_dict2.keys()

low_loss_values = history_dict2['loss']
low_val_loss_values = history_dict2['val_loss']
plt.plot(low_loss_values, 'bo', label='Training loss')
plt.plot(low_val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss low capacity')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

low_acc_values = history_dict2['accuracy']
low_val_acc_values = history_dict2['val_accuracy']
plt.plot(low_acc_values, 'bo', label='Training accuracy')
plt.plot(low_val_acc_values, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy low capacity')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()
######################################################################

model3 = Sequential()
model3.add(Dense(512, activation='relu', input_shape=(28 * 28,)))
model3.add(Dropout(0.5))
model3.add(Dense(64, activation='relu'))
model3.add(Dropout(0.5))
model3.add(Dense(10, activation='softmax'))

model3.compile (optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

history3=model3.fit(train_images , train_labels ,validation_data=(x_validation,y_validation),epochs=10, batch_size=128)

test_loss , test_accuracy = model3.evaluate(test_images , test_labels)
history_dict3 = history3.history
history_dict3.keys()

drop_loss_values = history_dict3['loss']
drop_val_loss_values = history_dict3['val_loss']
plt.plot(drop_loss_values, 'bo', label='Training loss')
plt.plot(drop_val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss using dropout')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

drop_acc_values = history_dict3['accuracy']
drop_val_acc_values = history_dict3['val_accuracy']
plt.plot(drop_acc_values, 'bo', label='Training accuracy')
plt.plot(drop_val_acc_values, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy usinf dropout')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

#####################################################################
model4 = Sequential()
model4.add(Dense(512,kernel_regularizer=regularizers.l1(0.001), activation='relu', input_shape=(28 * 28,)))
model4.add(Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))
model4.add(Dense(10, activation='softmax'))

model4.compile (optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

history4=model4.fit(train_images , train_labels ,validation_data=(x_validation,y_validation),epochs=10, batch_size=128)

test_loss , test_accuracy = model4.evaluate(test_images , test_labels)

history_dict4 = history4.history
history_dict4.keys()

l1_loss_values = history_dict4['loss']
l1_val_loss_values = history_dict4['val_loss']
plt.plot(l1_loss_values, 'bo', label='Training loss')
plt.plot(l1_val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss using l1')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

l1_acc_values = history_dict4['accuracy']
l1_val_acc_values = history_dict4['val_accuracy']
plt.plot(l1_acc_values, 'bo', label='Training accuracy')
plt.plot(l1_val_acc_values, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy using l1')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

##############################################################
model5 = Sequential()
model5.add(Dense(512,kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(28 * 28,)))
model5.add(Dense(64,kernel_regularizer=regularizers.l2(0.001), activation='relu'))
model5.add(Dense(10, activation='softmax'))

model5.compile (optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])
history5=model5.fit(train_images , train_labels ,validation_data=(x_validation,y_validation),epochs=10, batch_size=128)

test_loss , test_accuracy = model5.evaluate(test_images , test_labels)
history_dict5 = history5.history
history_dict5.keys()

l2_loss_values = history_dict5['loss']
l2_val_loss_values = history_dict5['val_loss']
plt.plot(l2_loss_values, 'bo', label='Training loss')
plt.plot(l2_val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss using l2')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

l2_acc_values = history_dict5['accuracy']
l2_val_acc_values = history_dict5['val_accuracy']
plt.plot(l2_acc_values, 'bo', label='Training accuracy')
plt.plot(l2_val_acc_values, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy using l2')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

################################################################

model6 = Sequential()
model6.add(Dense(512,kernel_regularizer=regularizers.l1_l2(0.001), activation='relu', input_shape=(28 * 28,)))
model6.add(Dense(64,kernel_regularizer=regularizers.l1_l2(0.001), activation='relu'))
model6.add(Dense(10, activation='softmax'))
 
model6.compile (optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

history6=model6.fit(train_images , train_labels ,validation_data=(x_validation,y_validation),epochs=10, batch_size=128)

test_loss , test_accuracy = model6.evaluate(test_images , test_labels)
 history_dict6 = history6.history
history_dict6.keys()
              
l1_l2_loss_values = history_dict6['loss']
l1_l2_val_loss_values = history_dict6['val_loss']
plt.plot(l1_l2_loss_values, 'bo', label='Training loss')
plt.plot(l1_l2_val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss using l1_l2')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

l1_l2_acc_values = history_dict6['accuracy']
l1_l2_val_acc_values = history_dict6['val_accuracy']
plt.plot(l1_l2_acc_values, 'bo', label='Training accuracy')
plt.plot(l1_l2_val_acc_values, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy using l1_l2')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

####################################################

plt.plot(org_acc_values,'bo',label='original accuracy')
plt.plot(low_acc_values,'r',label='low capacity accuracy')
plt.plot(drop_acc_values,'g',label='dropout accuracy')
plt.plot(l1_acc_values,'y',label='l1 accuracy')
plt.plot(l2_acc_values,'p',label='l2 accuracy')
plt.plot(l1_l2_acc_values,'b',label='l1_l2 accuracy')
plt.title('Training accuracy')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

plt.plot(org_val_acc_values,'bo',label='original accuracy')
plt.plot(low_val_acc_values,'r',label='low capacity accuracy')
plt.plot(drop_val_acc_values,'g',label='dropout accuracy')
plt.plot(l1_val_acc_values,'y',label='l1 accuracy')
plt.plot(l2_val_acc_values,'p',label='l2 accuracy')
plt.plot(l1_l2_val_acc_values,'b',label='l1_l2 accuracy')
plt.title('Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

plt.plot(org_loss_values,'bo',label='original loss')
plt.plot(low_loss_values,'r',label='low capacity loss')
plt.plot(drop_loss_values,'g',label='dropout loss')
plt.plot(l1_loss_values,'y',label='l1 loss')
plt.plot(l2_loss_values,'p',label='l2 loss')
plt.plot(l1_l2_loss_values,'b',label='l1_l2 loss')
plt.title('Training loss')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

plt.plot(org_val_loss_values,'bo',label='original loss')
plt.plot(low_val_loss_values,'r',label='low capacity loss')
plt.plot(drop_val_loss_values,'g',label='dropout loss')
plt.plot(l1_val_loss_values,'y',label='l1 loss')
plt.plot(l2_val_loss_values,'p',label='l2 loss')
plt.plot(l1_l2_val_loss_values,'b',label='l1_l2 loss')
plt.title('Validation loss')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.legend()
plt.show()


               


                  
                  
